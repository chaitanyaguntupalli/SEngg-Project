{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc48bb63",
   "metadata": {},
   "source": [
    "## Q. What are the most common prompts that developers ask ChatGPT? How does ChatGPT answer those prompts - Code or No Code?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6004c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary packages\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import string\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Ensure necessary components are downloaded\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fbd0b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'URL', 'Author', 'RepoName', 'RepoLanguage', 'Number', 'Title',\n",
       "       'Body', 'CreatedAt', 'ClosedAt', 'UpdatedAt', 'State',\n",
       "       'ChatgptSharing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the JSON file because of the complexity it has\n",
    "data = pd.json_normalize(pd.read_json(\"20231012_235128_issue_sharings.json\")[\"Sources\"])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227635d",
   "metadata": {},
   "source": [
    "**Considering the Issue Sharings file to test the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe44c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL', 'Status', 'DateOfConversation', 'DateOfAccess', 'Title',\n",
       "       'NumberOfPrompts', 'TokensOfPrompts', 'TokensOfAnswers', 'Model',\n",
       "       'Conversations', 'HTMLContent', 'Mention.MentionedURL',\n",
       "       'Mention.MentionedProperty', 'Mention.MentionedAuthor',\n",
       "       'Mention.MentionedText'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"20231012_235128_issue_sharings.json\")\n",
    "data = pd.json_normalize(data['Sources'])\n",
    "chatgpt_sharing_data = pd.json_normalize(data['ChatgptSharing'].explode())\n",
    "chatgpt_sharing_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a75c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLSL PHP PLpgSQL JavaScript Clojure F# Swift C++ MATLAB Objective-C Rust HTML Go Python Verilog C# Groovy Jupyter Notebook PowerShell C Shell TypeScript Nim Makefile None Perl Vue CSS Astro TeX R Zig Ruby Java Emacs Lisp Kotlin Game Maker Language\n"
     ]
    }
   ],
   "source": [
    "repo_lang = list(set(data[\"RepoLanguage\"]))\n",
    "print(*repo_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c23f2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prompt', 'Answer', 'ListOfCode'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"20231012_235128_issue_sharings.json\")\n",
    "data = pd.json_normalize(data['Sources'])\n",
    "chatgpt_sharing_data = pd.json_normalize(data['ChatgptSharing'].explode())\n",
    "first_column_data = chatgpt_sharing_data.iloc[:, 0]\n",
    "first_column_df = pd.DataFrame(first_column_data)\n",
    "expanded_chatgpt_sharing = data['ChatgptSharing'].apply(pd.Series).stack().reset_index(drop=True)\n",
    "all_attributes_chatgpt_sharing = pd.json_normalize(expanded_chatgpt_sharing)\n",
    "conversations_data = pd.json_normalize(all_attributes_chatgpt_sharing['Conversations'].explode())\n",
    "conversations_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3009710",
   "metadata": {},
   "source": [
    "## I asked ChatGPT what developers normally seek its assistance in.\n",
    "\n",
    "Developers often approach ChatGPT with a wide range of requests, typically revolving around programming, debugging, learning concepts, and development tools. To identify these questions, you can focus on keywords that are common in such contexts. Here are some common types of requests and corresponding keywords:\n",
    "\n",
    "1. **Coding Assistance**: \n",
    "   - **Keywords**: \"code\", \"write\", \"script\", \"implement\", \"function\", \"algorithm\".\n",
    "   - **Example**: \"Can you write a Python function to sort a list?\"\n",
    "\n",
    "2. **Debugging and Error Resolution**: \n",
    "   - **Keywords**: \"debug\", \"error\", \"fix\", \"issue\", \"resolve\", \"exception\", \"traceback\".\n",
    "   - **Example**: \"Help me debug this JavaScript error message I'm getting.\"\n",
    "\n",
    "3. **Explanation of Concepts**:\n",
    "   - **Keywords**: \"explain\", \"understand\", \"concept\", \"how does\", \"what is\", \"theory\", \"principle\".\n",
    "   - **Example**: \"Can you explain how recursion works in programming?\"\n",
    "\n",
    "4. **Learning and Educational Resources**:\n",
    "   - **Keywords**: \"learn\", \"tutorial\", \"course\", \"resource\", \"guide\", \"documentation\", \"example\".\n",
    "   - **Example**: \"Recommend some resources to learn React.\"\n",
    "\n",
    "5. **Best Practices and Design Patterns**:\n",
    "   - **Keywords**: \"best practice\", \"design pattern\", \"architecture\", \"efficient\", \"optimization\", \"structure\", \"model\".\n",
    "   - **Example**: \"What are some best practices for REST API design?\"\n",
    "\n",
    "6. **Technology and Tool Recommendations**:\n",
    "   - **Keywords**: \"recommend\", \"tool\", \"library\", \"framework\", \"technology\", \"platform\", \"software\".\n",
    "   - **Example**: \"Which libraries do you recommend for data visualization in Python?\"\n",
    "\n",
    "7. **Code Review and Optimization**:\n",
    "   - **Keywords**: \"review\", \"optimize\", \"improve\", \"enhance\", \"refactor\", \"performance\", \"efficiency\".\n",
    "   - **Example**: \"Can you review and suggest improvements for my Ruby script?\"\n",
    "\n",
    "8. **Project Guidance and Planning**:\n",
    "   - **Keywords**: \"plan\", \"approach\", \"strategy\", \"project\", \"structure\", \"organize\", \"develop\".\n",
    "   - **Example**: \"How should I plan the architecture for my mobile app project?\"\n",
    "\n",
    "9. **Integration and Configuration**:\n",
    "   - **Keywords**: \"integrate\", \"configure\", \"setup\", \"install\", \"deploy\", \"connect\", \"environment\".\n",
    "   - **Example**: \"How do I integrate a payment gateway in my web application?\"\n",
    "\n",
    "10. **Version Control and Collaboration**:\n",
    "    - **Keywords**: \"git\", \"version control\", \"collaborate\", \"merge\", \"branch\", \"commit\", \"repository\".\n",
    "    - **Example**: \"How do I resolve merge conflicts in Git?\"\n",
    "\n",
    "These keywords can help in identifying the nature of developers' questions. By focusing on these, you can categorize and address the specific needs of developer-related queries effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b848ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"code\", \"write\", \"script\", \"implement\", \"function\", \"algorithm\", \"debug\", \"error\", \n",
    "            \"fix\", \"issue\", \"resolve\", \"exception\", \"traceback\", \"explain\", \"understand\", \"concept\", \n",
    "            \"how does\", \"what is\", \"theory\", \"principle\", \"learn\", \"tutorial\", \"course\", \"resource\", \n",
    "            \"guide\", \"documentation\", \"example\", \"best practice\", \"design pattern\", \"architecture\", \n",
    "            \"efficient\", \"optimization\", \"structure\", \"model\", \"recommend\", \"tool\", \"library\", \n",
    "            \"framework\", \"technology\", \"platform\", \"software\", \"review\", \"optimize\", \"improve\", \n",
    "            \"enhance\", \"refactor\", \"performance\", \"efficiency\", \"plan\", \"approach\", \"strategy\", \n",
    "            \"project\", \"structure\", \"organize\", \"develop\",  \"integrate\", \"configure\", \"setup\", \n",
    "            \"install\", \"deploy\", \"connect\", \"environment\", \"git\", \"version control\", \"collaborate\", \n",
    "            \"merge\", \"branch\", \"commit\", \"repository\", \"generate\", 'GLSL','PHP','PLpgSQL', 'JavaScript', \n",
    "            'Clojure', 'F#','Swift','C++','MATLAB', 'Objective-C', 'Rust', 'HTML' 'Go',\n",
    " 'Python',\n",
    " 'Verilog',\n",
    " 'C#',\n",
    " 'Groovy',\n",
    " 'Jupyter Notebook',\n",
    " 'PowerShell',\n",
    " 'C',\n",
    " 'Shell',\n",
    " 'TypeScript',\n",
    " 'Nim',\n",
    " 'Makefile',\n",
    " 'Perl',\n",
    " 'Vue',\n",
    " 'CSS',\n",
    " 'Astro',\n",
    " 'TeX',\n",
    " 'R',\n",
    " 'Zig',\n",
    " 'Ruby',\n",
    " 'Java',\n",
    " 'Emacs Lisp',\n",
    " 'Kotlin',\n",
    " 'Game Maker Language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f42593bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_text(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Tokenize each sentence into words, remove stopwords and punctuation, and convert to lowercase\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english') + list(string.punctuation))\n",
    "    tokenized_sentences = [\n",
    "        [word.lower() for word in nltk.word_tokenize(sentence) if word.isalnum() and word.lower() not in stop_words]\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "\n",
    "    return tokenized_sentences\n",
    "\n",
    "def calculate_cosine_similarity(tfidf_matrix):\n",
    "    # Calculate cosine similarity between sentences based on TF-IDF matrix\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return similarity_matrix\n",
    "\n",
    "def generate_summary(text, num_sentences=3):\n",
    "    # Preprocess the text\n",
    "    tokenized_sentences = read_and_preprocess_text(text)\n",
    "\n",
    "    # Convert sentences to TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([' '.join(sentence) for sentence in tokenized_sentences])\n",
    "\n",
    "    # Calculate cosine similarity matrix\n",
    "    similarity_matrix = calculate_cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Use the PageRank algorithm to rank sentences\n",
    "    graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(graph)\n",
    "\n",
    "    # Sort sentences by their scores and select the top ones\n",
    "    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(tokenized_sentences)), reverse=True)\n",
    "    summary_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n",
    "\n",
    "    # Join the summary sentences to form the final summary\n",
    "    summary = ' '.join([' '.join(sentence) for sentence in summary_sentences])\n",
    "\n",
    "    return summary\n",
    "\n",
    "text = conversations_data[\"Prompt\"][12]\n",
    "\n",
    "summary = generate_summary(text, num_sentences=4).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03c9cd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write python3 script takes mp3 audio track generate beautiful audio visualizer video\n"
     ]
    }
   ],
   "source": [
    "print(*summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90a88170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ReplaceString': '[CODE_BLOCK_0]',\n",
       "  'Type': 'bash',\n",
       "  'Content': 'pip install moviepy numpy scipy matplotlib\\n'},\n",
       " {'ReplaceString': '[CODE_BLOCK_1]',\n",
       "  'Type': 'python',\n",
       "  'Content': 'import moviepy.editor as mp\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom moviepy.video.fx import fadein\\n\\n# Define your input MP3 audio file and output video file\\naudio_file = \"input_audio.mp3\"\\noutput_file = \"output_visualizer.mp4\"\\n\\n# Load the audio file\\naudio = mp.AudioFileClip(audio_file)\\n\\n# Set the duration of the video to match the audio\\nvideo = mp.VideoClip(lambda t: [0], duration=audio.duration)\\n\\n# Define a function to generate a frame for each moment in time\\ndef make_frame(t):\\n    # Get the audio data at the given time\\n    audio_data = audio.to_soundarray()[int(t * audio.fps)]\\n    \\n    # Create a simple audio visualizer using matplotlib\\n    plt.figure(figsize=(10, 4))\\n    plt.specgram(audio_data, Fs=audio.fps, cmap=\"viridis\")\\n    plt.axis(\\'off\\')\\n    \\n    # Save the plot to a temporary file\\n    plt.savefig(\"temp_frame.png\", bbox_inches=\\'tight\\', pad_inches=0, dpi=80)\\n    plt.close()\\n    \\n    # Load the frame as an image clip\\n    frame = mp.ImageClip(\"temp_frame.png\")\\n    \\n    return frame\\n\\n# Generate the visualizer video\\nvisualizer = video.fl(make_frame, duration=audio.duration)\\nvisualizer = fadein(visualizer, 1)  # Add a fade-in effect at the beginning\\n\\n# Write the video to the output file\\nvisualizer.write_videofile(output_file, fps=24)\\n\\n# Clean up temporary files\\nimport os\\nos.remove(\"temp_frame.png\")\\n'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_data[\"ListOfCode\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bfa257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write me python3 script that takes in mp3 audio track and generate a very beautiful audio visualizer video'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_data[\"Prompt\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1566dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script\n",
      "generate\n"
     ]
    }
   ],
   "source": [
    "for i in keywords:\n",
    "    if i in conversations_data[\"Prompt\"][12]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d50af28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write\n",
      "script\n",
      "generate\n"
     ]
    }
   ],
   "source": [
    "text = conversations_data[\"Prompt\"][12]\n",
    "generate_summary(text, num_sentences=4).split()\n",
    "for i in keywords:\n",
    "    if i in summary:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dd07ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ReplaceString': '[CODE_BLOCK_0]',\n",
       "  'Type': 'bash',\n",
       "  'Content': 'pip install moviepy numpy scipy matplotlib\\n'},\n",
       " {'ReplaceString': '[CODE_BLOCK_1]',\n",
       "  'Type': 'python',\n",
       "  'Content': 'import moviepy.editor as mp\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom moviepy.video.fx import fadein\\n\\n# Define your input MP3 audio file and output video file\\naudio_file = \"input_audio.mp3\"\\noutput_file = \"output_visualizer.mp4\"\\n\\n# Load the audio file\\naudio = mp.AudioFileClip(audio_file)\\n\\n# Set the duration of the video to match the audio\\nvideo = mp.VideoClip(lambda t: [0], duration=audio.duration)\\n\\n# Define a function to generate a frame for each moment in time\\ndef make_frame(t):\\n    # Get the audio data at the given time\\n    audio_data = audio.to_soundarray()[int(t * audio.fps)]\\n    \\n    # Create a simple audio visualizer using matplotlib\\n    plt.figure(figsize=(10, 4))\\n    plt.specgram(audio_data, Fs=audio.fps, cmap=\"viridis\")\\n    plt.axis(\\'off\\')\\n    \\n    # Save the plot to a temporary file\\n    plt.savefig(\"temp_frame.png\", bbox_inches=\\'tight\\', pad_inches=0, dpi=80)\\n    plt.close()\\n    \\n    # Load the frame as an image clip\\n    frame = mp.ImageClip(\"temp_frame.png\")\\n    \\n    return frame\\n\\n# Generate the visualizer video\\nvisualizer = video.fl(make_frame, duration=audio.duration)\\nvisualizer = fadein(visualizer, 1)  # Add a fade-in effect at the beginning\\n\\n# Write the video to the output file\\nvisualizer.write_videofile(output_file, fps=24)\\n\\n# Clean up temporary files\\nimport os\\nos.remove(\"temp_frame.png\")\\n'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_data[\"ListOfCode\"][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016e1e2",
   "metadata": {},
   "source": [
    "### Writing a function combining everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45fc85e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords found in summary are:  ['write', 'script', 'generate']\n",
      "\n",
      "\n",
      "Did ChatGPT provide code or no-code solution:\n",
      "ChatGPT provided code for the given prompt.\n"
     ]
    }
   ],
   "source": [
    "def read_and_preprocess_text(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Tokenize each sentence into words, remove stopwords and punctuation, and convert to lowercase\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english') + list(string.punctuation))\n",
    "    tokenized_sentences = [\n",
    "        [word.lower() for word in nltk.word_tokenize(sentence) if word.isalnum() and word.lower() not in stop_words]\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "\n",
    "    return tokenized_sentences\n",
    "\n",
    "def calculate_cosine_similarity(tfidf_matrix):\n",
    "    # Calculate cosine similarity between sentences based on TF-IDF matrix\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return similarity_matrix\n",
    "\n",
    "def generate_summary(text, num_sentences=3):\n",
    "    # Preprocess the text\n",
    "    tokenized_sentences = read_and_preprocess_text(text)\n",
    "\n",
    "    # Convert sentences to TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([' '.join(sentence) for sentence in tokenized_sentences])\n",
    "\n",
    "    # Calculate cosine similarity matrix\n",
    "    similarity_matrix = calculate_cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Use the PageRank algorithm to rank sentences\n",
    "    graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(graph)\n",
    "\n",
    "    # Sort sentences by their scores and select the top ones\n",
    "    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(tokenized_sentences)), reverse=True)\n",
    "    summary_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n",
    "\n",
    "    # Join the summary sentences to form the final summary\n",
    "    summary = ' '.join([' '.join(sentence) for sentence in summary_sentences])\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "text = conversations_data[\"Prompt\"][12]\n",
    "\n",
    "summary = generate_summary(text, num_sentences=4).split()\n",
    "\n",
    "keywords = [\"code\", \"write\", \"script\", \"implement\", \"function\", \"algorithm\", \"debug\", \"error\", \n",
    "            \"fix\", \"issue\", \"resolve\", \"exception\", \"traceback\", \"explain\", \"understand\", \"concept\", \n",
    "            \"how does\", \"what is\", \"theory\", \"principle\", \"learn\", \"tutorial\", \"course\", \"resource\", \n",
    "            \"guide\", \"documentation\", \"example\", \"best practice\", \"design pattern\", \"architecture\", \n",
    "            \"efficient\", \"optimization\", \"structure\", \"model\", \"recommend\", \"tool\", \"library\", \n",
    "            \"framework\", \"technology\", \"platform\", \"software\", \"review\", \"optimize\", \"improve\", \n",
    "            \"enhance\", \"refactor\", \"performance\", \"efficiency\", \"plan\", \"approach\", \"strategy\", \n",
    "            \"project\", \"structure\", \"organize\", \"develop\",  \"integrate\", \"configure\", \"setup\", \n",
    "            \"install\", \"deploy\", \"connect\", \"environment\", \"git\", \"version control\", \"collaborate\", \n",
    "            \"merge\", \"branch\", \"commit\", \"repository\", \"generate\"]\n",
    "\n",
    "keywords_in_summary = []\n",
    "for i in keywords:\n",
    "    if i in summary:\n",
    "        keywords_in_summary.append(i)\n",
    "print(\"Keywords found in summary are: \", keywords_in_summary)\n",
    "print(\"\\n\")\n",
    "print(\"Did ChatGPT provide code or no-code solution:\")\n",
    "if keywords_in_summary != []:\n",
    "    if conversations_data[\"ListOfCode\"][12] != []:\n",
    "        print(\"ChatGPT provided code for the given prompt.\")\n",
    "    else:\n",
    "        print(\"ChatGPT provided no-code solution for the given prompt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84d6a1",
   "metadata": {},
   "source": [
    "### Generalized code for all prompts in the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325df5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
